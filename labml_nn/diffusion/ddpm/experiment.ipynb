{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AahG_i2y5tY9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I5QyEuKgaP0k",
        "outputId": "95bbe8e7-c372-4153-8b52-6eec8a32e3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import cv2\n",
        "import string\n",
        "from keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import ReLU\n",
        "\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "IMRSQrMpatwI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = (256, 256, 3)\n",
        "latent_space = 256\n",
        "kernel = 3\n",
        "padding = 'same'\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 6e-8\n",
        "filter = 16\n",
        "strides = 1\n",
        "source_input = layers.Input(shape = image_shape, name = 'source')\n",
        "target_input = layers.Input(shape = image_shape, name = 'target')"
      ],
      "metadata": {
        "id": "HSAFekM7a-p3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "  z_mean, z_log_v = args\n",
        "  batch = tf.shape(z_mean)[0]\n",
        "  dim = tf.shape(z_mean)[1]\n",
        "  e = K.random_normal(shape = (batch, dim))\n",
        "  return z_mean + tf.exp(0.5*z_log_v)*e"
      ],
      "metadata": {
        "id": "S1X5PdNfbDg5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def module(inputs, filter, kernel, padding, strides, activation, use_norm, dilation_rate):\n",
        "    x = inputs\n",
        "    x = layers.Conv2D(filter, kernel_size = kernel, padding = padding, strides = strides,\n",
        "                    dilation_rate = dilation_rate)(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    if use_norm:\n",
        "        x = layers.GroupNormalization(groups = 1)(x)\n",
        "    x = layers.Conv2D(filter, kernel_size = kernel, padding = padding, strides = strides,\n",
        "                      dilation_rate = dilation_rate)(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    if use_norm:\n",
        "        x = layers.GroupNormalization(groups = 1)(x)\n",
        "    x = layers.Conv2D(filter, kernel_size = kernel, padding = padding, strides = strides,\n",
        "                      dilation_rate = dilation_rate)(x)\n",
        "    x = layers.Activation(activation)(x)\n",
        "    if use_norm:\n",
        "        x = layers.GroupNormalization(groups = 1)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vgeVOdnBbGYF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(inputs, filters, kernel, padding, strides, activation, use_norm, dilation_rate):\n",
        "    x = inputs\n",
        "    x = module(x, filters, kernel, padding, strides, activation, use_norm, dilation_rate)\n",
        "    y = layers.Conv2D(filters, kernel_size = 1, padding = padding, strides = strides,\n",
        "                                     activation = activation,)(inputs)\n",
        "    if use_norm:\n",
        "      y = layers.GroupNormalization(groups = 1)(y)\n",
        "\n",
        "    x = layers.maximum([x, y])\n",
        "    return x"
      ],
      "metadata": {
        "id": "6jOaPXgrbJve"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(inputs, filters, padding, strides, activation, kernel, use_norm, dilation_rate):\n",
        "    conv = convolution(inputs, filters, kernel, padding, strides, activation, use_norm, dilation_rate)\n",
        "    return layers.MaxPooling2D()(conv), conv\n",
        "def decoder(inputs, skip, filters, padding, strides, kernel, activation, use_norm, dilation_rate):\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size = kernel, padding = padding,\n",
        "                              strides = 2, activation = activation,)(inputs)\n",
        "    x = layers.maximum([x, skip])\n",
        "    x = convolution(x, filters, kernel ,padding, strides, activation, use_norm, dilation_rate)\n",
        "    return x"
      ],
      "metadata": {
        "id": "b9giEMBXbMhN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def U_net(inputs, filter, padding, strides, activation, kernel, use_norm, name, weights, latent_space_name):\n",
        "    x = inputs\n",
        "    conv1, skip1 = encoder(x, filter, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv2, skip2 = encoder(conv1, filter*2, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv3, skip3 = encoder(conv2, filter*4, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv4, skip4 = encoder(conv3, filter*8, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv5, skip5 = encoder(conv4, filter*16, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv6, skip6 = encoder(conv5, filter*32, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    conv7, skip7 = encoder(conv6, filter*64, padding, strides, activation[0], kernel, use_norm, 1)\n",
        "    x = layers.Flatten()(conv6)\n",
        "    z_mean = tf.keras.layers.Dense(latent_space, name = \"z_mean_{}\".format(latent_space_name))(x)\n",
        "    z_log_v = tf.keras.layers.Dense(latent_space, name = \"z_log_v_{}\".format(latent_space_name))(x)\n",
        "    x = tf.keras.layers.Lambda(sampling,\n",
        "                               output_shape = (latent_space,), name = latent_space_name)([z_mean, z_log_v])\n",
        "    x = layers.Dense(conv7.shape[1]*conv7.shape[2]*conv7.shape[3],\n",
        "                    kernel_regularizer = tf.keras.regularizers.L2(0.0001),\n",
        "                    activation = activation[1])(x)\n",
        "    x = layers.Reshape((conv7.shape[1], conv7.shape[2], conv7.shape[3]))(x)\n",
        "    dec0 = decoder(x, skip7, filter*64, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec = decoder(dec0, skip6, filter*32, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec1 = decoder(dec, skip5, filter*16, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec2 = decoder(dec1, skip4, filter*8, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec3 = decoder(dec2, skip3, filter*4, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec4 = decoder(dec3, skip2, filter*2, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    dec5 = decoder(dec4, skip1, filter, padding, strides, kernel, activation[1], use_norm, 1)\n",
        "    output = layers.Conv2DTranspose(3, kernel_size = kernel, padding = padding,\n",
        "                                   strides = 1,)(dec5)\n",
        "    output = layers.Activation('sigmoid')(output)\n",
        "    m = models.Model(inputs = inputs, outputs = output,\n",
        "                    name = name)\n",
        "    if weights:\n",
        "      if name == 'xTOy':\n",
        "          m.load_weights('/gdrive/My Drive/g_target_5_27.h5')\n",
        "      elif name == 'yTOx':\n",
        "          m.load_weights('/gdrive/My Drive/g_source_5_27.h5')\n",
        "    return m"
      ],
      "metadata": {
        "id": "yHEQJA4tbbg-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator(inputs, filter, padding, strides, kernel, activation, use_norm,\n",
        "                 name, weights):\n",
        "    x = inputs\n",
        "    conv1, skip1 = encoder(x, filter, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv2, skip2 = encoder(conv1, filter*2, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv3, skip3 = encoder(conv2, filter*4, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv4, skip4 = encoder(conv3, filter*8, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv5, skip5 = encoder(conv4, filter*16, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv6, skip6 = encoder(conv5, filter*32, padding, strides, activation, kernel, use_norm, 1)\n",
        "    conv7, skip7 = encoder(conv6, filter*64, padding, strides, activation, kernel, use_norm, 1)\n",
        "    output1 = layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                         strides = 1)(conv5)\n",
        "    output2 = layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                         strides = 1)(conv4)\n",
        "    output3 = layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                         strides = 1)(conv3)\n",
        "    output = layers.Conv2D(1, kernel_size = kernel, padding = padding, strides = 1,\n",
        "                           )(conv7)\n",
        "    output = layers.add([\n",
        "        output,\n",
        "        layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                      activation = activation)(layers.MaxPooling2D((4, 4))(conv5)),\n",
        "        layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                      activation = activation)(layers.MaxPooling2D((6, 6))(conv4)),\n",
        "        layers.Conv2D(1, kernel_size = kernel, padding = padding,\n",
        "                      activation = activation)(layers.MaxPooling2D((11, 11))(conv3))\n",
        "    ])\n",
        "    m = models.Model(inputs = inputs, outputs = [output, output1, output2, output3], name = name)\n",
        "    if weights:\n",
        "      if name == 'xx':\n",
        "          m.load_weights('/gdrive/My Drive/d_source_5_27.h5')\n",
        "      elif name == 'yy':\n",
        "          m.load_weights('/gdrive/My Drive/d_target_5_27.h5')\n",
        "    return m"
      ],
      "metadata": {
        "id": "pmqn60ABbni9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_target = U_net(source_input, filter, padding,\n",
        "                        strides, ['LeakyReLU', 'relu'], kernel, use_norm = True,\n",
        "                        name = 'xTOy', weights = True, latent_space_name = 'target_latent_space')\n",
        "g_source = U_net(target_input, filter, padding, strides,\n",
        "                       ['LeakyReLU', 'relu'], kernel, use_norm = True,\n",
        "                       name = 'yTOx', weights = True, latent_space_name = 'source_latent_space')"
      ],
      "metadata": {
        "id": "b6z7D6-Xg2Of",
        "outputId": "b16dde3e-4ee4-499d-df25-e3448f432aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret activation function identifier: LeakyReLU",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-195e3a6e4c5e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g_target = U_net(source_input, filter, padding,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LeakyReLU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         name = 'xTOy', weights = True, latent_space_name = 'target_latent_space')\n\u001b[1;32m      4\u001b[0m g_source = U_net(target_input, filter, padding, strides,\n\u001b[1;32m      5\u001b[0m                        \u001b[0;34m[\u001b[0m\u001b[0;34m'LeakyReLU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-c2a0d2f40cc3>\u001b[0m in \u001b[0;36mU_net\u001b[0;34m(inputs, filter, padding, strides, activation, kernel, use_norm, name, weights, latent_space_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mU_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_space_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ba93f9dc9c6a>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(inputs, filters, padding, strides, activation, kernel, use_norm, dilation_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     x = layers.Conv2DTranspose(filters, kernel_size = kernel, padding = padding,\n",
            "\u001b[0;32m<ipython-input-7-6032c37c3161>\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, filters, kernel, padding, strides, activation, use_norm, dilation_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     y = layers.Conv2D(filters, kernel_size = 1, padding = padding, strides = strides,\n\u001b[1;32m      5\u001b[0m                                      activation = activation,)(inputs)\n",
            "\u001b[0;32m<ipython-input-6-dd45c239b987>\u001b[0m in \u001b[0;36mmodule\u001b[0;34m(inputs, filter, kernel, padding, strides, activation, use_norm, dilation_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m     x = layers.Conv2D(filter, kernel_size = kernel, padding = padding, strides = strides,\n\u001b[1;32m      4\u001b[0m                     dilation_rate = dilation_rate)(x)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activation, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;34mf\"Could not interpret activation function identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret activation function identifier: LeakyReLU"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Denoising Diffusion Probabilistic Models (DDPM)",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}